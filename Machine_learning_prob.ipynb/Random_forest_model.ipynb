{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Random Forest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eloboration\n",
    "1. Random forest is an ensemble classifier combining classifier that uses and combining many decision tree\n",
    "2. ensembling is usually done using the concept of baging with different feature set\n",
    "3. The reason for using large number of trees in random forest is also to train the trees enough such that contribution from each feature comes in a number of models\n",
    "4. The result from the ensemble model is usually better than that from the individual decision tree model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strength\n",
    "\n",
    "1. It runs efficiently on large and expensive data set\n",
    "2. It has robust method for estimating the missing data and maintain the precision of the data is absent\n",
    "3. It has powerfull technique for balancing the error in a class and population of unbalanced data sets\n",
    "4. It gives the estimation about which feature are most important ones on overall classification\n",
    "5. Lastly random forest algorithm can be used to solve both classification and regression problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weakness of random forest\n",
    "1. It is not an easy task to understand the random forest as decision tree model\n",
    "2. It take more computational power than the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "data = pd.read_csv('apndcts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>At1</th>\n",
       "      <th>At2</th>\n",
       "      <th>At3</th>\n",
       "      <th>At4</th>\n",
       "      <th>At5</th>\n",
       "      <th>At6</th>\n",
       "      <th>At7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.213</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.187</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.289</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.449</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.427</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.462</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       At1    At2    At3    At4    At5    At6    At7\n",
       "0    0.213  0.554  0.207  0.000  0.000  0.749  0.220\n",
       "1    0.458  0.714  0.468  0.111  0.102  0.741  0.436\n",
       "2    0.102  0.518  0.111  0.056  0.022  0.506  0.086\n",
       "3    0.187  0.196  0.105  0.056  0.029  0.133  0.085\n",
       "4    0.236  0.804  0.289  0.111  0.066  0.756  0.241\n",
       "..     ...    ...    ...    ...    ...    ...    ...\n",
       "101  0.449  0.875  0.523  0.083  0.076  0.920  0.487\n",
       "102  0.102  0.000  0.022  0.000  0.000  0.000  0.017\n",
       "103  0.409  0.875  0.482  0.306  0.259  0.914  0.443\n",
       "104  0.427  0.804  0.474  0.056  0.048  0.836  0.437\n",
       "105  0.462  0.911  0.551  0.167  0.154  0.931  0.500\n",
       "\n",
       "[106 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = data.iloc[:,0:7]\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "101    0\n",
       "102    0\n",
       "103    0\n",
       "104    0\n",
       "105    0\n",
       "Name: class, Length: 106, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data.iloc[:,7]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train,predictors_test,target_train,target_test = train_test_split(\n",
    "    predictors,target,test_size = 0.3,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf  = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model = rf.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction use the trained model\n",
    "prediction = rf.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time to check the prediction accuracy\n",
    "accuracy_score(target_test,prediction,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  0],\n",
       "       [ 3,  4]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time to check the confusion matrix too\n",
    "confusion_matrix(target_test,prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy = TP + TN / TP+FP+FN+TN\n",
    "model accracy = 25 + 4/32= 0.90625\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensitivity is model measure the proportion of Positive casse\n",
    "sensitivity = TP / TP+FN \n",
    "sensitivity = 25/28 = 0.8928\n",
    "\n",
    "###### The high value of sensitivity is more desireable than a high value of accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specify is also another good measure to indicate a good balance of a model being excessvely conservative or excessvely aggresive\n",
    "\n",
    "specificity = TN/TN+FP \n",
    "specificity = 4/4+0 = 1\n",
    "\n",
    "A higher value of specificity will indicate a better model performance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### percision\n",
    "percision gives the proportion of positive predicion which are truly positive\n",
    "percision = TP/TP+FP\n",
    "percision = 25/25+0=1=100%\n",
    "\n",
    "It is quite understand that model higherpercision is precieved to be more reliable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "Recal the indicate the proportion of correct prediction of positive to the total number of positives\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "Recall = 25/28= 0.89"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-measure\n",
    "F-measure is another measure of model performance which combine the percision and recall it takes harmonic means of percision and recall\n",
    "\n",
    "F-measure = 2*percision*recall/percision + recall\n",
    "F-measure = 2*1*0.89/1+0.89\n",
    "F-measure = 1.78/1.89\n",
    "F-measure = 0.9418 = 94%\n",
    "\n",
    "As a combination of multiple measure into one F-score gives the right  measure using which perfomance of different model can be compared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py34",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
